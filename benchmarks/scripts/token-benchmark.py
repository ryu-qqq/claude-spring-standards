#!/usr/bin/env python3
"""
Token Usage Benchmark Tool

Ï∫êÏãú ÏãúÏä§ÌÖú vs ÎπÑÏ∫êÏãú ÏãúÏä§ÌÖúÏùò ÌÜ†ÌÅ∞ ÏÇ¨Ïö©ÎüâÏùÑ ÎπÑÍµê Ï∏°Ï†ïÌï©ÎãàÎã§.

Usage:
    python3 token-benchmark.py [--layer domain|application|adapter-rest]
"""

import os
import sys
import json
import glob
from pathlib import Path
from typing import Dict, List, Tuple

# ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏ ÎîîÎ†âÌÜ†Î¶¨
PROJECT_ROOT = Path(__file__).parent.parent.parent
CACHE_DIR = PROJECT_ROOT / ".claude" / "cache" / "rules"
DOCS_DIR = PROJECT_ROOT / "docs" / "coding_convention"

# ÌèâÍ∑† ÌÜ†ÌÅ∞/KB ÎπÑÏú® (Í≤ΩÌóòÏ†Å Ï∂îÏ†ïÍ∞í)
TOKENS_PER_KB = 250


def get_file_size_kb(file_path: Path) -> float:
    """ÌååÏùº ÌÅ¨Í∏∞Î•º KB Îã®ÏúÑÎ°ú Î∞òÌôò"""
    return os.path.getsize(file_path) / 1024


def estimate_tokens(size_kb: float) -> int:
    """ÌååÏùº ÌÅ¨Í∏∞Î°úÎ∂ÄÌÑ∞ ÌÜ†ÌÅ∞ Ïàò Ï∂îÏ†ï"""
    return int(size_kb * TOKENS_PER_KB)


def measure_cache_scenario(layer: str = None) -> Dict:
    """Cache ÏãúÏä§ÌÖú ÏãúÎÇòÎ¶¨Ïò§ Ï∏°Ï†ï"""
    cache_files = []

    if layer:
        # ÌäπÏ†ï Î†àÏù¥Ïñ¥Ïùò Ï∫êÏãú ÌååÏùºÎßå
        pattern = f"{layer}-*.json"
        cache_files = list(CACHE_DIR.glob(pattern))
    else:
        # Î™®Îì† Ï∫êÏãú ÌååÏùº
        cache_files = [f for f in CACHE_DIR.glob("*.json") if f.name != "index.json"]

    total_size_kb = sum(get_file_size_kb(f) for f in cache_files)
    total_tokens = estimate_tokens(total_size_kb)

    return {
        "scenario": "Cache System",
        "layer": layer or "all",
        "file_count": len(cache_files),
        "total_size_kb": round(total_size_kb, 2),
        "estimated_tokens": total_tokens,
        "files": [f.name for f in cache_files]
    }


def measure_non_cache_scenario(layer: str = None) -> Dict:
    """Non-Cache ÏãúÏä§ÌÖú ÏãúÎÇòÎ¶¨Ïò§ Ï∏°Ï†ï (Ï†ÑÏ≤¥ ÎßàÌÅ¨Îã§Ïö¥ Î°úÎî©)"""
    md_files = []

    if layer:
        # ÌäπÏ†ï Î†àÏù¥Ïñ¥Ïùò Î¨∏ÏÑúÎßå
        if layer == "domain":
            layer_dir = "02-domain-layer"
        elif layer == "application":
            layer_dir = "03-application-layer"
        elif layer == "adapter-rest":
            layer_dir = "01-adapter-rest-api-layer"
        else:
            layer_dir = f"*{layer}*"

        layer_path = DOCS_DIR / layer_dir
        md_files = list(layer_path.rglob("*.md"))
    else:
        # Î™®Îì† ÎßàÌÅ¨Îã§Ïö¥ Î¨∏ÏÑú
        md_files = list(DOCS_DIR.rglob("*.md"))

    total_size_kb = sum(get_file_size_kb(f) for f in md_files)
    total_tokens = estimate_tokens(total_size_kb)

    return {
        "scenario": "Non-Cache System",
        "layer": layer or "all",
        "file_count": len(md_files),
        "total_size_kb": round(total_size_kb, 2),
        "estimated_tokens": total_tokens,
        "files": [f.name for f in md_files]
    }


def calculate_savings(cache_result: Dict, non_cache_result: Dict) -> Dict:
    """Ï†àÍ∞ê Ìö®Í≥º Í≥ÑÏÇ∞"""
    cache_tokens = cache_result["estimated_tokens"]
    non_cache_tokens = non_cache_result["estimated_tokens"]

    saved_tokens = non_cache_tokens - cache_tokens
    savings_percent = (saved_tokens / non_cache_tokens * 100) if non_cache_tokens > 0 else 0

    return {
        "tokens_saved": saved_tokens,
        "savings_percent": round(savings_percent, 2),
        "size_reduction_kb": round(
            non_cache_result["total_size_kb"] - cache_result["total_size_kb"], 2
        )
    }


def run_benchmark(layer: str = None) -> Dict:
    """Ï†ÑÏ≤¥ Î≤§ÏπòÎßàÌÅ¨ Ïã§Ìñâ"""
    print(f"\n{'='*60}")
    print(f"  Token Usage Benchmark")
    print(f"  Layer: {layer or 'ALL'}")
    print(f"{'='*60}\n")

    # Cache ÏãúÎÇòÎ¶¨Ïò§ Ï∏°Ï†ï
    print("üìä Measuring Cache System...")
    cache_result = measure_cache_scenario(layer)
    print(f"   Files: {cache_result['file_count']}")
    print(f"   Size: {cache_result['total_size_kb']} KB")
    print(f"   Tokens: ~{cache_result['estimated_tokens']:,}")

    # Non-Cache ÏãúÎÇòÎ¶¨Ïò§ Ï∏°Ï†ï
    print("\nüìä Measuring Non-Cache System...")
    non_cache_result = measure_non_cache_scenario(layer)
    print(f"   Files: {non_cache_result['file_count']}")
    print(f"   Size: {non_cache_result['total_size_kb']} KB")
    print(f"   Tokens: ~{non_cache_result['estimated_tokens']:,}")

    # Ï†àÍ∞ê Ìö®Í≥º Í≥ÑÏÇ∞
    print("\nüí∞ Calculating Savings...")
    savings = calculate_savings(cache_result, non_cache_result)
    print(f"   Tokens Saved: ~{savings['tokens_saved']:,}")
    print(f"   Savings: {savings['savings_percent']}%")
    print(f"   Size Reduction: {savings['size_reduction_kb']} KB")

    # Í≤∞Í≥º Ï†ÄÏû•
    result = {
        "timestamp": "2025-10-17",
        "layer": layer or "all",
        "cache_system": cache_result,
        "non_cache_system": non_cache_result,
        "savings": savings
    }

    # JSON Ï†ÄÏû•
    output_file = PROJECT_ROOT / "benchmarks" / "results" / "token-comparison.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(result, f, indent=2, ensure_ascii=False)

    print(f"\n‚úÖ Results saved to: {output_file}")
    print(f"\n{'='*60}\n")

    return result


def main():
    """Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò"""
    layer = None

    if len(sys.argv) > 1:
        if sys.argv[1] == "--layer" and len(sys.argv) > 2:
            layer = sys.argv[2]
            if layer not in ["domain", "application", "adapter-rest", "all"]:
                print(f"‚ùå Invalid layer: {layer}")
                print("   Valid options: domain, application, adapter-rest, all")
                sys.exit(1)

            if layer == "all":
                layer = None

    run_benchmark(layer)


if __name__ == "__main__":
    main()
